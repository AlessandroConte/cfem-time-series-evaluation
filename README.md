# CFEM: Composite Forecasting Evaluation Metric for Time Series Models

ğŸ“ Bachelor's Thesis Project â€“ BSc in Computer Science  
ğŸ“ University of Venice â€“ Academic Year 2023/2024  
ğŸ‘¨â€ğŸ’» Author: Alessandro Conte  
ğŸ“˜ Advisor: Prof. Ilaria Prosdocimi  

---

## ğŸ“ Project Overview

This repository contains the implementation and explanation of a **composite metric (CFEM)** for evaluating forecasting models on time series data. The metric combines four traditional error measures (RMSE, MAE, MAPE, MASE), addressing their individual limitations and enhancing comparability across different datasets and models.

The work was developed as part of a thesis internship at **Humco**, and includes the design, implementation, and testing of the metric on real datasets using models like **ARIMA, SARIMA, Holt-Winters, and Prophet**.

ğŸ“„ [Read the full thesis (PDF, Italian)](./thesis.pdf)

---

## ğŸ“Š Main Objectives

- Design a unified metric that balances the strengths and weaknesses of standard error measures.
- Normalize and weigh the metrics based on data characteristics (trend, seasonality, outliers).
- Evaluate the metric on real-world datasets with different models.
- Discuss its robustness and future improvements.

---

## ğŸ“‚ Repository Structure

ğŸ“ cfem-time-series-evaluation/
â”œâ”€â”€ README.md <- You are here
â”œâ”€â”€ thesis.pdf <- Full thesis document (Italian)
â”œâ”€â”€ notebook/
â”‚ â””â”€â”€ cfem_notebook.ipynb <- Google Colab notebook with full implementation
â”œâ”€â”€ src/
â”‚ â””â”€â”€ utils.py <- Optional: utility functions
â”œâ”€â”€ data/
â”‚ â””â”€â”€ sample_data.csv <- Optional: if publicly shareable
â””â”€â”€ requirements.txt <- Optional: dependencies for running the code

---

## ğŸ”§ Models and Tools

- Forecasting Models: ARIMA, SARIMA, Holt-Winters, Prophet
- Libraries: `pandas`, `numpy`, `matplotlib`, `statsmodels`, `fbprophet`, `scikit-learn`
- Validation: Expanding Window Cross-Validation
- Notebook: [Google Colab Compatible]

---

## ğŸ“ˆ CFEM Formula

The **Composite Forecasting Evaluation Metric (CFEM)** is defined as:

```math
CFEM = (Î£ wáµ¢ * máµ¢) / Î£ wáµ¢
```

Where:

* `máµ¢` = normalized value of each error metric (Min-Max normalization)
* `wáµ¢` = weight computed based on:

  * Seasonality strength (via STL decomposition)
  * Median or mean error across CV folds
  * Metric-specific significance (depending on data characteristics)

---

## ğŸ“Œ Future Work

* Improve the robustness of the weight computation
* Test the metric on more complex datasets
* Package CFEM as a reusable Python module

---

## ğŸ“¬ Contact

Feel free to connect with me on [LinkedIn](https://www.linkedin.com/in/alessandro-conte-ds/) or reach out for collaboration.

````

